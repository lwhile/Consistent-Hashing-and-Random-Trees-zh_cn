# 一致性哈希与随机树：一种用于缓解万维网热点问题的分布式缓存协议

## 摘要
我们介绍了用于分布式网络的缓存协议族，可以解决或消除网络上热点的发生。我们的协议特别针对大型网络来设计的，例如因热点引起的延迟非常严重的因特网和每个服务器都无法获得有关整个网络当前状态的完整信息的大型网络。这个协议用现存网络的协议例如tcp/ip来实现很简单，并且开销很小。协议通过节点自身进行控制，无需额外节点实现（The protocols work with local control），高效利用现存资源并随着网络的发展可以很优雅的拓展。

我们的协议基于一种特殊的哈希算法，我们叫它一致性哈希算法。大致来说，只需要微小的改动就可以适用大部分场景。有了优秀的一致性哈希函数，我们能开发出不需要用户拥有当前甚至一致的网络视图的缓存协议。我们坚信一致性哈希函数能最终被证实它对其他应用例如分布式域名解析服务器（ distributed name
servers ）或quorum机制是有作用的。

## 1 介绍

在这篇论文里，我们介绍多种用于在分布式网络中减少或者消除热点问题发生的缓存协议。当多个客户端同时访问同一个服务器的时，热点问题随时都有可能发生。如果站点无法同时为所有的客户同时提供服务，那么服务很有可能会被严重影响甚至发生故障。

我们中的许多人在使用网络的时候都经历过热点现象。一个网络站点可能会突然间变得很流行并在短时间内收到大量的请求，这远远超出了它最开始所赋予的处理能力。实际上，一个站点可能就收到许多请求以至于其变得无法使用。除了让某个站点无法访问，大量的集中到某个位置的流量还可能会导致其附近的网络发生拥堵，干扰到附近站点的流量。

随着网络的普及，热点问题发生的可能性与影响都随之增大。最近几个有名的热点故障的例子包括 在休梅克－利维 9 号彗星与木星相撞后的JPL（美国喷射推进实验室） 的站点，深蓝与卡斯帕罗夫的国际象棋比赛时的 IBM 站点，以及选举之夜的政府网站。这些站点中的一部分导致用户在几个小时甚至几天的时间内被站点拒绝访问。其他例子包括那些“今日站点”或者提供流行软件更新的站点。

我们最开始的工作动机就是解决由于热点导致的万维网问题。我们相信我们开发的工具可能会对许多 CS 模型有帮助，因为许多互联网中心化的互联网服务包括 DNS、多播服务、以及内容标记服务都对热点问题很敏感。

## 1.1 过去的做法

过去有几种推荐的解决热点问题的方法，绝大多数都是利用某种复制策略在网络上存储热页面（#TODO）的副本；这增大了在多个服务器上提供热页面的工作。还有一种方法，仍被广泛使用，那就是多个客户端上分享代理缓存（#TODO）。所有的客户端要把请求发送给缓存了高频访问页面副本的代理服务器。它试图缓存副本来满足请求；缓存命中失败才把请求发送给主服务器。这种方案的缺点就是用户越多作用越大，用户太少的话没有起多大作用，而缓存的本身也更容易被淹没（TODO）。

Malpani等人想要把一组缓存函数封装成一个来解决这个问题（#TODO）。用户的一个页面请求直接去到任意一份缓存。如果页面存在，就直接返回给用户。否则，缓存通过一个叫“IP Multicast”的特殊协议发送其他所有的缓存。如果所有缓存都没有这个页面，请求会发送到该页面所在的主站。这个方案的坏处就在于，参与的缓存越来越多，即使用组播，缓存之前的信息也会变得越来越难维护。我们将在第四节讨论这篇论文所介绍的一致性哈希，它提供了一种方法去实现这种无需通信的分布式缓存。

Chankhunthod等人研究并完善了Harvest缓存，一个高可拓展性的树形结构缓存。用户通过最近的叶子节点的缓存获取页面。如果这个节点包括它的兄弟节点都没有这个页面，请求才会发往父节点，查看缓存有无此页面，以此类推。如果这一整个树都没有此页面，请求最终会达到根节点并且发往该页面所在的主站。缓存会保留请求过的页面一段时间。树形结构的缓存的优点在于缓存接收到的请求只会从子节点（或兄弟节点）传过来，这样确保不会有太多的请求同时到达。因此，在有一个页面短时间内被很多客户端请求的情况下，只有一个请求发往这个页面的服务器，其他请求直接使用缓存。而且也不会使缓存不堪重负。对于这个方案，理论上上有一个缺点，那就是同一棵树会应用整个页面，意味着从根节点开始，每个不同页面都要请求一遍，从而建立一整棵树（#TODO）。这让根节点陷入困境，如果项目发展到后面，慢慢地有太多不同的页面请求，意味着这个体系也有潜在的可拓展问题（#TODO）。

Plaxton 和 Rajaraman [9] 则向世人说明通过使用随机性和哈希如何平衡所有缓存的加载。实际上，他们为每个页面使用越来越大的“虚拟缓存站点”的层级结构并且在网络上使用随机哈希函数为每个虚拟站点分配对应实际的缓存（#TODO）。客户端发送一个请求到层级结构的任一组随机节点。当某个缓存过载时，被分配到的给定集会把页面的副本给到较大的、较近的的集合中。这样的话对于那些频繁被客户端请求的页面也能做到快速响应。因为页面的最大的集合不会过载（#TODO）。它也提供了良好的负载平衡，因为小集合满了之后会把缓存复制到大的集合中，然后小集合的数据就清空，大集合就拥有小集合的数据，但不会过载（#TODO）。Plaxton和Rajaraman的技术也具有容错能力。

然而Plaxton/Rajaraman算法也是有缺点的。因为他们的算法会把每个页面的副本请求发送到每个集合的随机节点，用于热点页面的小集合将会很快过载（#TODO）。事实上，这个算法就是用过载作为标志来触发复制转移的。这在同步并联系统模式下很管用，因为在这种模式下会假定过载的程序接收传入消息的子集，在其他方面正常运作（#TODO）。然而在网络上，过载的机器会带来严重的问题，过载机器无法自行恢复运作并且甚至会宕机。此外，在大量的机器之间有意并且随机选择某些机器进入过载状态，对于运维人员来说并不是件有利的事。Plaxton/Rajaraman算法也是需要同步通信和消息拥有优先级，这样使得一组缓存的可用性得到修复并且也对所有用户可见了。

## 1.2 我们的做法

从这里开始，我们将介绍两种用于数据复制的工具，并且我们用这两种工具来实现一种缓存算法，该算法克服了前面1.1所介绍的方法的缺点并且还额外提供了几个不错的特性。

我们的第一个工具，随机缓存树，融合了Chankhunthod等人的树形结构缓存（以下称Chankhunthod算法）和Plaxton/Rajaraman算法的结构设计。跟
Chankhunthod算法一样，我们使用树形结构缓存合并请求。跟Plaxton/Rajaraman算法一样，我们基于随机哈希函数通过为每个页面使用不同的树并将树节点分配给缓存来平衡负载。我们用自己的方法结合Chankhunthod算法和Plaxton/Rajaraman算法最好的特性，做到了不让服务器那么频繁的宕机和过载，这是Chankhunthod算法和Plaxton/Rajaraman算法做不到的。此外，我们仅仅通过缓存被请求一定次数的页面来做到最小化内存占用（并不会明显地降低缓存命中率）。

我们认为引入缓存树的额外延迟在实际使用中应该特别小。请求页面的时间随着树的深度成倍增加。然而，典型的页面请求花费的时间都是很小的，以至于如果树的深度太深，访问树的时间比直接请求的时间还要长，就得不偿失了。页面的返回可以流水线化；缓存不需要等到它向树的子节点发送数据之前才接收整个页面。因此，页面的返回也是需要一些时间的。 总而言之，用户感受到的额外延迟是很小的。

我们的第二个工具是一个新的哈希策略，我们叫它一致性哈希。一致性哈希策略与Plaxton/Rajaraman算法和其他实际系统中所用的哈希方法大不相同。通过已知固定集合服务器，已知的基于典型哈希方法的方案已经能够很好的实现分布式加载。然而在互联网上却没有固定的服务器（译者注：可能是说今天是这几台服务器，明天是另外几台服务器）。相反，机器会因为崩溃了或者其他原因停止服务，或者被其他机器代替。更糟糕的是，关于机器的信息在网络上传播的很慢，由于不知道那个机器可以备份数据，导致客户出现不兼容的“页面”（#TODO）。由于典型的哈希方法要求客户端要有专门提供特定页面的缓存，这让典型的哈希方法变得不是很有用。举个例子，Feeley等人实现了用于在网络上的智能终端的分布式全局共享内存系统。这个系统是基于不同机器间实现分布式哈希表解决引用问题。每次有新机器加入时，需要一个主服务器取为所有机器重新计算哈希表。

一致性哈希有助于解决此类问题。跟大多数哈希策略类似，一致性哈希会用桶（译者注：类似桶排序的桶）来分配一组数据，以致于每个容器能够接收大致相等数量的数据。不同于标准的哈希策略，桶里面的数据改变一小部分（译者注：原文是small change）并不会引起整个数据的重新映射。此外，将数据散列到一组略有不同的桶中，只会引起桶中数据的分配有些不一样（#TODO）。我们应用一致性哈希到我们的缓存树体系中，即使每个客户端都只知道所有缓存机器的固定的一小部分，一致性哈希也能让这个缓存树体系很好的工作。Litwin等人[5]建议哈希函数能够有序地添加桶。然而，目前我们的哈希函数是允许乱序添加桶的。这个的话我们能够根据Devine[2]的方案来改进的。此外，我们相信，这些需要多台机器做服务提供、多台机器有着不同的网络视图的应用，通过我们的一致性哈希，无需通信就能知道共同存储对象的位置。（例如quorum机制[7][8]或者分布式名字服务器）

## 1.3 介绍

我们将在第2节介绍我们的模型如何解决网络上的热点问题。我们的模型虽然比较简单，但是它足够全面，在实践中，可以利用它来发展或分析我们认为有用的协议。在第三节，我们将介绍我们的随机生成树的方法并将它应用到缓存协议中，在简单的模型下，能够有效地消除热点。随后，在第四节里，基于第三节的基础上，我们将呈现我们的一致性哈希方法并用它解决不同简单模型下，不同视图的热点问题。

在第五节，我们展示怎么样将我们的两个技术有效地结合在一起。在第六节，我们提出了一个简单的延迟模型，用来捕获接入网络的机器的分层聚类。我们将展示我们的协议能够很容易扩展到更多得现实延迟模型中。在第七和第八节，我们分别制定在超时的时候，协议要如何处理错误以及应做出的行为。在第九节，我们来一起讨论一些拓展性问题和一些开放问题。

## 1.4 关于随机化和哈希的注记

在某些应用场景中，我们使用哈希函数降对象映射到指定范围中。为了简单清楚起见，我们那假设这些函数都是真正随机的方式映射对象的，即一致性和独立性。在实践中，那些只有有限独立性的哈希函数貌似更具有可行性，因为它有效利用了空间和随机性。我们已经使用了类似[11]中的方法证明了这篇论文中的所有理论只有有限独立性。然而，在这段摘要中，我们只说明结果所需的独立程度。证明假设有限独立性将会在本论文的完整版给出。

## 2 model

wu translate

## 3 随机树

在这一节，我们先介绍第一个工具，随机树。为了简单起见，我们在一个较为简单的环境下使用个简单的缓存协议。实际上，我们对模型做了以下简化：

* 全部机器都拥有全份缓存
* δ(m<sub>i</sub>, m<sub>j</sub>) = 1 for all i ≠ j
* 同时发起全部请求

在只有一批请求的意义上，这种受限制的模型是静态的；我们不需要考虑网络稳定性。

在这些限制条件下，我们将介绍一个表现优秀的协议，能使机器不那么高概率宕机。我们达到了Θ(logC)的总延迟时间，并证明了它是最优的。我们将一部分的请求塞进缓存里，并平均分配（#TODO）。在随后的章节我们将介绍如何拓展协议以便在没有简化假设的情况下保持良好的表现。

我们协议的基本思想就是文中一开始在 introduction 章节中中讨论的缓存树的拓展。我们使用这棵树来确保在获取特定页面的缓存时不会嵌套太深。正如 introduction 章节讨论的那样，根节点附近的缓存页面会被访问很多次，即使缓存的是不常用的页面，这导致了根节点容易过载。我们的技术与 Plaxton/Rajaraman 的相似，为每个页面使用不同的、随机的算法来生成一颗树。这确保了靠近根节点的机器不会提供大量的页面缓存，这样就实现了良好的负载均衡。但是请注意，我们无法利用 Plaxton/Rajaraman 给出的分析，因为我们的主要目的是防止机器宕机，而它们是允许机器宕机，然后解决机器宕机的问题。

在接下来的3.1章节，我们精确定义了我们的协议。在3.2章节，我们分析协议，
